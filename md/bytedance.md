# 字节跳动面试题解析

## MySQL

#### 存储引擎

##### MyISAM

特点：

- 并发性和锁级别 （对于读写混合的操作不好，为表级锁，写入和读互斥）
- 表损坏修复
- Myisam 表支持的索引类型（全文索引）
- Myisam 支持表压缩（压缩后，此表为只读，不可以写入。使用 myisampack 压缩）
- 不支持事务和行级锁，不支持外键，并且索引和数据是分开存储的

##### InnoDB

mysql5.5及之后版本默认的存储引擎

特点：

- 事务性存储引擎，完全支持ACID

- Redo log实现事务的持久性，undo log实现回滚

- 支持行级锁

- 行级锁可以最大程度的支持并发

- 行级锁是由存储引擎层实现的

### 索引

采用B+树数据结构存储索引。

B+树的非叶子节点存储key+指向下一节点的指针，叶子节点之间通过链表相互链接

B树的非叶子节点存储key+key指向的数据+指向下一节点的指针

所以说B+树非叶子节点能存储更多的key，且利于范围查询，而B树要做中序遍历

索引的存储形式有聚簇索引和非聚簇索引，其中聚簇索引是表中的主键索引，如果没有主键索引，那么使用表中的唯一索引，如果还没有，innodb会默认创建一个隐式的主键。

非聚簇索引存储的是key和指向聚簇索引的的主键

所以如果通过非聚簇索引查询数据，它要先去非聚簇索引查询到主键ID的值，然后再去聚簇索引里查找对应的数据地址。这就是mysql里的回表现象。

当然，如果非聚簇索引包含了要查询的所有键，那么不需要回表查询，这种现象叫做索引覆盖。

### 锁的类型有哪些

mysql锁分为**共享锁**和**排他锁**，也叫做读锁和写锁。

读锁是共享的，可以通过lock in share mode实现，这时候只能读不能写。

写锁是排他的，它会阻塞其他的写锁和读锁。从颗粒度来区分，可以分为**表锁**和**行锁**两种。

表锁会锁定整张表并且阻塞其他用户对该表的所有读写操作，比如alter修改表结构的时候会锁表。

行锁又可以分为**乐观锁**和**悲观锁**，悲观锁可以通过for update实现，乐观锁则通过版本号实现。

### 事务特性和隔离级别

事务基本特性ACID分别是：

- 原子性

- 一致性

- 隔离性

- 持久性

隔离级别分别是：

- read uncommit: 读未提交，可能会读到其他事务未提交的数据，也叫做脏读。

- read commit：读已提交，两次读取结果不一致，叫做不可重复读。**不可重复读解决了脏读问题**，它只会读取已经提交的事务。

- repeatable read： 可重复读，这是mysql的默认级别，就是每次读取结果都一样，但是**有可能产生幻读**。间隙锁+MVCC解决幻读问题

- serializable：串行，一般是不会使用的，它会给每一行读取的数据加锁，会导致大量超时和锁竞争的问题。

#### ACID靠什么保证

A原子性由undo log日志保证，它记录了需要回滚的日志信息，事务回滚时撤销已经执行成功的sql

C一致性靠AID来保证

I隔离性由MVCC来保证

D持久性由内存+redo log来保证，mysql修改数据同时在内存和redo log记录这次操作，事务提交的时候通过redo log刷盘，宕机的时候可以从redo log恢复。

### MVCC

MVCC(Multi Version Concurrency Control)： 多版本并发控制，实际上就是保存了数据在某个时间点的快照。

### readview

- read uncommitted隔离级别事务：直接读取记录的最新版本；

- serializable隔离级别事务：使用加锁的方式来访问记录；

- RC和RR隔离级别事务：需要用到版本链概念，核心问题是如何判断版本链中哪个版本是当前事务可见的？

- readview中四个比较重要的概念：

- m_ids：表示在生成readview时，当前系统中活跃的读写事务id列表；

- min_trx_id：表示在生成readview时，当前系统中活跃的读写事务中最小的事务id，也就是m_ids中最小的值；

- max_trx_id：表示生成readview时，系统中应该分配给下一个事务的id值；

- creator_trx_id：表示生成该readview的事务的事务id；

- 有了readview，在访问某条记录时，按照以下步骤判断记录的某个版本是否可见

- 1、如果被访问版本的trx_id，与readview中的creator_trx_id值相同，表明当前事务在访问自己修改过的记录，该版本可以被当前事务访问；

- 2、如果被访问版本的trx_id，小于readview中的min_trx_id值，表明生成该版本的事务在当前事务生成readview前已经提交，该版本可以被当前事务访问；

- 3、如果被访问版本的trx_id，大于或等于readview中的max_trx_id值，表明生成该版本的事务在当前事务生成readview后才开启，该版本不可以被当前事务访问；

- 4、如果被访问版本的trx_id，值在readview的min_trx_id和max_trx_id之间，就需要判断trx_id属性值是不是在m_ids列表中？

- 如果在：说明创建readview时生成该版本的事务还是活跃的，该版本不可以被访问

- 如果不在：说明创建readview时生成该版本的事务已经被提交，该版本可以被访问；

- 生成readview时机

- RC隔离级别：每次读取数据前，都生成一个readview；

- RR隔离级别：在第一次读取数据前，生成一个readview；

https://zhuanlan.zhihu.com/p/66791480

### 日志种类，主从同步机制，数据延迟

 日志种类 https://database.51cto.com/art/201806/576300.htm

- bin log 主要用于主从同步，把sql命令顺序写入日志
- undo log 主要实现事务的原子行
- redo log 主要实现事务的持久性
- relay log 主要用于主从同步，重放sql命令
- error log 主要查看错误日志
- slow query log 主要查看慢查询sql日志
- general log

##### redolog

1. 作用
   确保事务的持久性

防止在发生故障的时候，尚有脏页未写入磁盘（数据库的更新操作不会把数据立刻更新到磁盘，而是先更新缓存池中的数据），在重启mysql服务的时候，根据redo log进行重做，从而满足事务的持久性。

2. 内容
   物理格式的日志，记录的是物理数据页面的修改信息，其redo log是顺序写，所有很快

3. 什么时候产生
   事务提交前先写入redolog，顺序写很快，然后再提交事务

4. 什么时候释放
   对应的事物脏页被刷新到磁盘之后，redolog就可以被重用了

#### 主从复制

主从复制主要涉及三个线程：binlog线程、I/O线程和SQL线程

- binlog线程： 负责将主服务器上的数据更改写入二进制文件（binlog）中

- I/O线程：负责从主服务器上读取二进制日志文件，并写入从服务器的中继日志中

- SQL线程：负责读取中继日志并重放其中的SQL

![](http://image.dillonliang.cn/mybook/mysql-master-slave.jpg)

**从库同步主库数据库的过程是串行化的**，也就是说主从数据有一定的延时。如果主库突然宕机了，恰好数据还没有同步到从库，那么数据可能在从库上是没有的，数据丢失。

为了解决数据延时的问题，mysql提供了两种机制：

- 半同步复制： 指的是主库写入biglog日志之后，就会强制将数据同步到从库，从库将日志写入本地的relay log之后，接着会返回一个ack给主库，主库接收到至少一个从库的ack之后才会认为写操作完成
- 并行复制： 从库开多个线程，并行读取relay log中不同库的日志，然后**并行重放不同库的日志**，这是库级别的并行。

Note：
半同步复制减少了数据的丢失，但增加了额外的等待时间开销
半同步复制的过程中，主库宕机了，可能出现幻读的问题，即主库已提交并被读取数据，从库未同步完成，此时主库宕机，从库升为master，就有幻读的问题。
并行复制减小了数据延迟，但仍有数据丢失的可能

**异步复制**就是最上面所说的有从库读取二进制文件，并写入本地中继日志里，主库执行完事务后立刻返回
**全同步复制**就是主库要等所有从库复制了数据后才返回，严重影响性能

### 分库分表

账户600万*28

充值600万*28

购买记录700万 28库 128表

购买记录单条： 600万

金币日志：9000万 16个库

简单来说，数据的切分就是通过某种特定的条件，将我们存放在同一个数据库中的数据分散存放到多个数据库（主机）中，以达到分散单台设备负载的效果，即分库分表。

数据的切分根据其切分规则的类型，可以分为如下两种切分模式。

- 垂直（纵向）切分：把单一的表拆分成多个表，并分散到不同的数据库（主机）上。
- 水平（横向）切分：根据表中数据的逻辑关系，将同一个表中的数据按照某种条件拆分到多台数据库（主机）上。

### 读写分离

主服务器用来处理写操作以及实时性要求比较高的读操作，而从服务器用来处理读操作。

读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。

MySQL 读写分离能提高性能的原因在于：

- 主从服务器负责各自的读和写，极大程度缓解了锁的争用；
- 从服务器可以配置 MyISAM 引擎，提升查询性能以及节约系统开销；
- 增加冗余，提高可用性。

![](http://image.dillonliang.cn/mybook/mysql-read-write.jpg)

### 死锁

- 超时处理

- 死锁检测

### MYSQL 主从服务器，如果主服务器是InnoDB引擎，从服务器是MyISAM引擎，应用中会遇到什么问题？

- 1.MyISAM表锁，所以每次插入都会锁表一次。

- 2.MyISAM不支持事务，备份时可能会丢失数据。

## Redis

#### 基本数据类型

- 字符串：sds

- 链表linkedlist

- 字典hashtable

- 跳跃表skiplist

- 整数集合intset

- 压缩列表ziplist

#### 为什么这么快

单机redis可以支撑每秒10几万的并发，主要因为如下几点：

- 完全基于内存操作

- C语言实现，优化过的数据结构，基于几种基础的数据结构，redis做了大量的优化，性能极高

- 使用单线程，无上下文的切换成本

- 基于非阻塞的I/O多路复用机制

#### 为什么Redis6.0之后又改用多线程呢？

redis使用多线程并非是完全摒弃单线程，redis还是使用单线程模型来处理客户端的请求，只是使用多线程来处理数据的读写和协议解析，执行命令还是使用单线程。

这样做的目的是因为redis的性能瓶颈在于网络IO而非CPU，使用多线程能提升IO读写的效率，从而整体提高redis的性能。

#### 热key问题

所谓热key问题就是，突然有几十万的请求去访问redis上的某个特定key，那么这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机引发雪崩。

解决方案：

1。 主从redis服务器，把热key打散到不同的服务器

2。 加入二级缓存，提前加载热key数据到内存中，如果redis宕机，走内存查询。

#### 缓存击穿

是指单个key并发访问过高，过期时导致所有请求直接打到DB上，关注点在过期瞬间

解决方案：

1。 加锁更新，防止其他请求同时请求数据库，只需等待即可

2。 将过期时间组合写在value中，通过异步的方式不断的刷新过期时间，防止此类现象。

#### 缓存穿透

是指查询不存在缓存中的数据，每次请求都会打到DB，就像缓存不存在一样。

解决方案：

1。 布隆过滤器，bit

2。 设置一个默认值，（如果有新值，先删缓存，再新增）

#### 缓存雪崩

是指发生大规模的缓存失效的情况，比如说redis服务器宕机，缓存都过期了

解决方案：

1。 针对不同key设置不同的过期时间，避免同时过期

2。 限流/熔断，如果redis宕机，可以限流，避免同时刻大量请求打崩DB

3。二级缓存，同热key的方案

#### 过期策略有哪些

- 惰性删除： 用的时候检查是否过期

- 定期删除： 定时去随机扫描key

redis采用惰性删除+定期删除的策略

#### 内存淘汰机制有哪些

惰性删除+定期删除也不一定删除无效的key，这时需要走内存淘汰机制：

1. noeviction: 当内存达到阀值，新写入报错

2. allkeys-random: 从key中随机选择并淘汰

3. allkeys-lru: 从key中选择最近最少使用的进行淘汰

4. volatile-random: 从设置过期时间的key中随机淘汰

5. volatile-lru: 从设置过期时间的key中，移除最近最少使用的进行淘汰

6. volatile-ttl: 从设置过期时间的key中，移除将要过期的key

#### 持久化

RDB/AOF

#### 高可用

- 主从架构（主宕机，需要手动处理，非自动故障转移）

- 哨兵（占用机器，可以自动故障转移，集群监控，消息通知）

#### 集群（高并发）

redis集群是redis提供的分布式数据存储方案，集群通过数据分片sharding来进行数据的共享，同时提供复制和故障转移的功能。

主从复制： [Redis主从复制的配置和实现原理 - 掘金](https://juejin.im/post/6844903943764443149)

### 压缩用什么算法

lzf，压缩列表

### Redis如果list较大，怎么优化

## MQ

#### 如何保证消息队列的高可用

RabbitMQ有三种模式：

- 单机模式
- 普通集群模式
- 镜像集群模式

##### 单机模式

单机模式无高可用性，demo级别，

##### 普通集群模式

普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。

优点：

1. 提高了吞吐量

缺点：

1. MQ集群内部可能产生大量的数据传输（数据所在的节点和消费者连接的节点不是同一个）
2. 可用性无保障，queue所在节点宕机了，数据就没了（需要配合持久化使用）

##### 镜像集群模式

**真正的高可用模式**

跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。

优点：

1. 高可用，单节点宕机不影响消息的消费

缺点：

1. 扩展性比较差，新增节点并不能扩展性能
2. 每个节点都有全部的元数据和消息

#### 如何保证消息不被重复消费

换句话说，就是如何保证幂等性
这个要根据具体的业务来分析：

- 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。
- 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
- 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
- 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

#### 如何保证消息的可靠性传输

如何处理消息丢失的问题？

消息丢失可能在生产者，MQ，消费者中。

1. **生产者丢失消息**，怎么办？可以通过开启rabbitmq 事务的方式
   事务都有一个特性，要么成功，要么失败回滚，失败了就再次发一次

2. **Rabbitmq丢失数据**，就是 RabbitMQ 自己弄丢了数据，这个你必须开启 RabbitMQ 的持久化，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，可能导致少量数据丢失，但是这个概率较小。

设置持久化有两个步骤：

创建 queue 的时候将其设置为持久化
这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。

第二个是发送消息的时候将消息的 deliveryMode 设置为 2
就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。

必须要同时设置这两个持久化才行，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。

注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。

所以，持久化可以跟生产者那边的 confirm 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 ack 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 ack ，你也是可以自己重发的。

3. **消费者丢失消息**，RabbitMQ 如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。

这个时候得用 RabbitMQ 提供的 ack 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 ack ，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 ack 一把。这样的话，如果你还没处理完，不就没有 ack 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。

![此处输入图片的描述][7]

#### 如何保证消息的顺序性

①拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；这样也会造成吞吐量下降，可以在消费者内部采用多线程的方式取消费。
![此处输入图片的描述][8]

②或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理

----------

#### 如何设计MQ

从高可用、可扩展、持久化、分布式考虑

#### 如何处理消息积压

1个queue拆分为多个queue，每个queue启多个消费者，消费完后改为原有架构

## RPC调用过程

## 垃圾回收算法

### 引用计数

优点：

1。 及时清理内存

缺点：

1。 需要存储引用计数

2。 无法处理循环引用

3。 非线程安全的处理引用计数

4。 浪费CPU资源，即使内存够用，仍然在运行时进行计数器的统计

### 标记清除

解决了引用计数垃圾回收算法的缺点，但是也带来新的缺点

1。 全面扫描，非及时清除

2。 内存碎片问题

### 标记整理

优点：

1。 解决了内存碎片的问题

缺点：

1。 每一次整理内存空间后，各存活对象按照相对的前后位置从初始位置开始重新连续地分配内存空间，代码中内存地址的改变势必会带来大量额外的逻辑运算处理，来保证内存移动后，代码中的地址也能正确的更新，

2。 不可预测的内存地址改变会给调试程序增加难度。

### 复制算法

复制算法的核心就是，将原有的内存空间一分为二，每次只用其中的一块，在垃圾回收时，将正在使用的对象复制到另一个内存空间中，然后将该内存空间清空，交换两个内存的角色，完成垃圾的回收。  
如果内存中的垃圾对象较多，需要复制的对象就较少，这种情况下适合使用该方式并且效率比较高，反之，则不适合。

优点 ： 1、在垃圾对象多的情况下，效率较高。 2、清理后，内存无碎片。

 缺点 ： 1、在垃圾对象少的情况下，不适用，如 ：老年代内存。 2、分配的2块内存空间，在同一时刻，只能使用一半，内存使用率较低。

### 分代算法

前面介绍了很多种回收算法，每一种算法都有自己的优点也有缺点，谁都不能替代谁，所以根据垃圾回收对象的特点进行选择，才是明智的选择。 分代算法其实就是这样的，根据回收对象的特点进行选择，在jvm中，年轻代适合使用复制算法，老年代适合使用标记清除或标记压缩算法。

## HTTP / HTTP2 / HTTPS

http请求的整个链路

301/302区别

cookie/session/csrf及防御方法

长链接/短链接

dns劫持



### HTTP2 



#### 流量控制

Window_update 帧，没有可用空间时，发送带有END_STREAM标记的长度为0的帧



## Linux

#### TCP

##### 什么是TCP？

TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。

- **面向连接**：一定是「一对一」才能连接，不能像 UDP 协议 可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；

- **可靠的**：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；

- **字节流**：消息是「没有边界」的，所以无论我们消息有多大都可以进行传输。并且消息是「有序的」，当「前一个」消息没有收到的时候，即使它先收到了后面的字节已经收到，那么也不能扔给应用层去处理，同时对「重复」的报文会自动丢弃。

##### 什么是TCP连接？

**用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗口大小称为连接。**

##### TCP三次握手

- 一开始，客户端和服务端都处于 `CLOSED` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态
- 客户端会随机初始化序号（`client_isn`），将此序号置于 TCP 首部的「序号」字段中，同时把 `SYN` 标志位置为 `1` ，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 `SYN-SENT` 状态。
- 服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（`server_isn`），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `client_isn + 1`, 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 `SYN-RCVD` 状态。
- 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次「确认应答号」字段填入 `server_isn + 1`，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 `ESTABLISHED` 状态。
- 服务器收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。

从上面的过程可以发现**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**

一旦完成三次握手，双方都处于 `ESTABLISHED` 状态，此致连接就已建立完成，客户端和服务端就可以相互发送数据了。

##### 如何在Linux系统中查看TCP状态？

```bash
netstat -napt
```

##### 为什么是三次握手？而不是两次、四次？

接下来以三个方面分析三次握手的原因：

- 三次握手才可以阻止历史重复连接的初始化（主要原因）

- 三次握手才可以同步双方的初始序列号

- 三次握手才可以避免资源浪费

TCP 建立连接时，通过三次握手**能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号**。序列号能够保证数据包不重复、不丢弃和按序传输。

不使用「两次握手」和「四次握手」的原因：

- 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；

- 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

##### TCP头部格式

**序列号**：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。**用来解决网络包乱序问题。**

**确认应答号**：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。**用来解决不丢包的问题。**

**控制位：**

- *ACK*：该位为 `1` 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 `SYN` 包之外该位必须设置为 `1` 。

- *RST*：该位为 `1` 时，表示 TCP 连接中出现异常必须强制断开连接。

- *SYC*：该位为 `1` 时，表示希望建立连，并在其「序列号」的字段进行序列号初始值的设定。

- *FIN*：该位为 `1` 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 `FIN` 位置为 1 的 TCP 段。

##### SYN攻击

我们都知道 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的 SYN 接收队列（未连接队列）**，使得服务器不能为正常用户服务。

##### 避免SYN攻击方式

1。 修改内核参数，超出的SYN直接回RST，丢弃连接

2。 启动cookie，检查ACK包的合法性

##### TCP四次挥手

- 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。

- 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSED_WAIT` 状态。

- 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。

- 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。

- 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态

- 服务器收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。

- 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。

你可以看到，每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。

这里一点需要注意是：**主动关闭连接的，才有 TIME_WAIT 状态。**

##### 为什么挥手需要四次？

再来回顾下四次挥手双方发 `FIN` 包的过程，就能理解为什么需要四次了。

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。

- 服务器收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK`和 `FIN` 一般都会分开发送，从而比三次握手导致多了一次。

##### 为什么TIME_WAIT等待的时间是2MSL？

TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是：网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以**一来一回需要等待 2 倍的时间**。

##### 为什么需要TIME_WAIT状态？

主动发起关闭连接的一方，才会有 `TIME-WAIT` 状态。

需要 TIME-WAIT 状态，主要是两个原因：

- 防止具有相同「四元组」的「旧」数据包被收到；

- 保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭；

##### TIME_WAIT过多有什么危害？

过多的 TIME-WAIT 状态主要的危害有两种：

- 第一是内存资源占用；

- 第二是对端口资源的占用，一个 TCP 连接至少消耗一个本地端口；

##### 如果已经建立了连接，但是客户端突然出现故障了怎么办？

TCP 有一个机制是**保活机制**。这个机制的原理是这样的：

定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。

### tcp的沾包与半包

***\*粘包\**/\**拆包的原因\****

1. 要发送的数据大于**TCP**发送缓冲区剩余空间大小，将会发生**拆包**。
2. 待发送数据大于MSS（最大报文长度），**TCP**在传输前将进行**拆包**。
3. 要发送的数据小于**TCP**发送缓冲区的大小，**TCP**将多次写入缓冲区的数据一次发送出去，将会发生**粘包**。
4. 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生**粘包**。

解决方法：

1. 首部添加数据包长度

2. 每个数据包固定长度，不够的话填充

3. 数据包之间设置边界

   

### tcp可靠性传输

TCP 是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的。

##### 重传机制

TCP 针对数据包丢失的情况，会用**重传机制**解决。

常见的重传机制如下：

- 超时重传

- 快速重传

- SACK

- D-SACK

超时重传的情况：数据包丢失或者确认应答丢失

![](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/5.jpg)

![](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/7.jpg)

- 当超时时间 **RTO 较大**时，重发就慢，丢了老半天才重发，没有效率，性能差；

- 当超时时间 **RTO 较小**时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。

快速重传

![](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/10.jpg)

##### 滑动窗口

发送-应答的方式效率低，往返时间越长，通信效率越低

窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。

这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。

所以，通常窗口的大小是由接收方的窗口大小来决定的。

##### 流量控制

发送方不能无脑的发数据给接收方，要考虑接收方处理能力。

如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。

为了解决这种现象发生，**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**

##### 拥塞控制

在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大....

控制的目的就是**避免「发送方」的数据填满整个网络。**

#### Socket编程

过程如下：

- 服务端和客户端初始化 `socket`，得到文件描述符；

- 服务端调用 `bind`，将绑定在 IP 地址和端口;

- 服务端调用 `listen`，进行监听；

- 服务端调用 `accept`，等待客户端连接；

- 客户端调用 `connect`，向服务器端的地址和端口发起连接请求；

- 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；

- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；

- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

### UDP/Websocket

#### SIP会话初始协议

### select/poll/epoll

### 进程间通信

### 用户线程和系统线程，系统线程切换为什么这么慢

### 虚拟内存和物理内存怎么映射

1. 虚拟内存空间的管理，将虚拟内存分成大小相等的页；
2. 物理内存的管理，将物理内存分成大小相等的页；
3. 内存映射，将虚拟内存页和物理内存页映射起来，并且在内存紧张的时候可以换出到硬盘中；
4. 虚拟地址分为两部分，页号和页内偏移；页号作为页表的索引，页表包含物理页每页所在物理内存的基地址。这个基地址与页内偏移的组合就形成了物理内存地址；
5. 32位系统下，虚拟地址有页目录表和页表项，前10位定位到页目录表中的一项（页表，包含1k项），再用中间10位定位到页表中的一项（页，大小4K），再用最后12位定位到页中具体位置（页内偏移量）
6. 64位系统下，虚拟地址有全局页目录项PGD（Page Global Directory）、上层页目录项PUD（Page Upper Directory）、中间页目录项PMD（Page Middle Directory）和页表项PTE（Page Table Entry）

### linux删除文件夹下的所有日志，递归

### 自旋锁是什么？为什么要用？用户态和内核态切换要做什么？上下文切换主要做了什么？

自旋锁与互斥锁

- 自旋锁与互斥锁都是为了实现保护资源共享的机制。

- 无论是自旋锁还是互斥锁，在任意时刻，都最多只能有一个保持者。

- 获取互斥锁的线程，如果锁已经被占用，则该线程将进入睡眠状态；获取自旋锁的线程则不会睡眠，而是一直循环等待锁释放。
  
  总结：

- 自旋锁：线程获取锁的时候，如果锁被其他线程持有，则当前线程将循环等待，直到获取到锁。

- 自旋锁等待期间，线程的状态不会改变，线程一直是用户态并且是活动的(active)。

- 自旋锁如果持有锁的时间太长，则会导致其它等待获取锁的线程耗尽CPU。

- 自旋锁本身无法保证公平性，同时也无法保证可重入性。

- 基于自旋锁，可以实现具备公平性和可重入性质的锁。

- TicketLock:采用类似银行排号叫好的方式实现自旋锁的公平性，但是由于不停的读取serviceNum，每次读写操作都必须在多个处理器缓存之间进行缓存同步，这会导致繁重的系统总线和内存的流量，大大降低系统整体的性能。

- CLHLock和MCSLock通过链表的方式避免了减少了处理器缓存同步，极大的提高了性能，区别在于CLHLock是通过轮询其前驱节点的状态，而MCS则是查看当前节点的锁状态。

- CLHLock在NUMA架构下使用会存在问题。在没有cache的NUMA系统架构中，由于CLHLock是在当前节点的前一个节点上自旋,NUMA架构中处理器访问本地内存的速度高于通过网络访问其他节点的内存，所以CLHLock在NUMA架构上不是最优的自旋锁。

### 查询文件中出现次数最多的url(linux命令)

## 微服务

### 限流方案

### 一致性哈希

### 服务治理有哪些模块

### 注册中心原理

### 为什么配置中心也属于服务治理

### 链路监控的原理

#### 全链路压测怎么做，遇到了什么问题

## 分布式

### 分布式锁

### 分布式事务

- 二次提交

- TCC

- 补偿机制

- 事务性消息

### 分布式存储

## 系统设计

### 短链设计

### 网站排查问题

### 10亿视频，平均50弹幕

### 秒杀系统设计

### 健康码更新定位原理

### 分库分表方案，淘宝订单场景，能按卖家ID和卖家ID+订单ID查询

### 任意精度的延时队列怎么设计？堆的插入时间复杂度是多少？

### 微博点赞场景，能查用户点赞记录、不能重复点赞、能查当天热榜Top10

### 设计直播送礼系统

### 设计微信红包系统

## 算法题

### 迷宫回路（回溯搜索）

### 二叉树遍历，不允许标记访问过的节点，且只用一个栈

### 股票买卖

### 打印出二叉树所有和为N的路径

### 贪心算法

#### 数字刚好大一个数字

### 子集

#### 返回该数组所有可能的子集（幂集）

```go
func subsets(nums []int) [][]int {
    sort.Slice(nums, func(i, j int) bool {
        return nums[i] < nums[j]
    })
    r := make([][]int, 0)
    r = append(r, []int{})
    count := 0

    for count < len(nums) {
        tempR := make([][]int, 0)
        for _, v := range r {
            temp := make([]int, 0)
            temp = append(temp, v...)
            temp = append(temp, nums[count])
            tempR = append(tempR, temp)
        }
        count++

        for _, i := range tempR {
            r = append(r, i)
        }
    }

    return r
}
```

### 链表：奇数生序，偶数降序

### 64匹赛马

### LC152 乘积最大子数组

### 一个长字符串，一个不重复的字符串数组，找到一个子串，内容与数组相同

### 岛屿问题

### 搬家

### 最大子数组，子数组可以组成顺子

### 组合： 1-26对于a-z字母，组合情况

### 二叉树的子结构

### 9个人一个骰子一份礼物，公平的送礼

### 多路归并，数组求子数组最大和

### 手写快排

### 判断对此二叉树

### 堵塞队列、堆排序、第k大的数字

### 找出字符串中没有重复字符串的最长子串的长度？

### 一个数组、一个目标值，求连续子数组，是（目标值-连续子数组和）最小，双指针

### 单链表，每N个一组进行翻转

### 大数减法

### 链表

#### 两数相加

```go
/**
 * Definition for singly-linked list.
 * type ListNode struct {
 *     Val int
 *     Next *ListNode
 * }
 */
func addTwoNumbers(l1 *ListNode, l2 *ListNode) *ListNode {
    result := &ListNode{0, nil}
    carry := 0
    cur := result

    for l1 != nil || l2 != nil {
        tem := 0
        if l1 != nil {
            tem += l1.Val
            l1 = l1.Next
        }

        if l2 != nil {
            tem += l2.Val
            l2 = l2.Next
        }

        c := (tem + carry) / 10
        nodeVal := (tem + carry) % 10
        node := &ListNode{nodeVal, nil}
        carry = c
        cur.Next = node
        cur = node
    }

    if carry > 0 {
        cur.Next = &ListNode{carry, nil}
    }

    return result.Next
}
```

#### 翻转链表

```go
/**
 * Definition for singly-linked list.
 * type ListNode struct {
 *     Val int
 *     Next *ListNode
 * }
 */
func reverseList(head *ListNode) *ListNode {
    if head == nil || head.Next == nil {
        return head
    }

    var pre *ListNode
    var current *ListNode

    var next = head

    for next != nil {
        current = next.Next
        next.Next = pre
        pre = next
        next = current
    }

    return pre
}
```

#### 链表中倒数第K个节点

```go
/**
 * Definition for singly-linked list.
 * type ListNode struct {
 *     Val int
 *     Next *ListNode
 * }
 */
func getKthFromEnd(head *ListNode, k int) *ListNode {
    if head == nil || k <= 0 {
        return nil
    }

    var quick = head
    var slow = head
    var count = 0

    for quick != nil {
        if count == k {
            quick = quick.Next
            slow = slow.Next
        } else {
            quick = quick.Next
            count++
        }
    }

    return slow
}
```

#### 删除链表的倒数第N个节点

```go
/**
 * Definition for singly-linked list.
 * type ListNode struct {
 *     Val int
 *     Next *ListNode
 * }
 */
func removeNthFromEnd(head *ListNode, n int) *ListNode {
    if n == 0 || n == 1 {
        return nil
    }
    var quick *ListNode = head
    var slow *ListNode = head
    var slowPre *ListNode = head
    for i := 0; i < n - 1; i++ {
        quick = quick.Next
    }

    for quick != nil && quick.Next != nil {
        quick = quick.Next
        slowPre = slow
        slow = slow.Next
    }

    slowPre.Next = slow.Next
    return head
}
```

#### 链表中倒数第K个节点

#### 删除链表的倒数第N个节点

#### 合并两个排序的链表

```go
/**
 * Definition for singly-linked list.
 * type ListNode struct {
 *     Val int
 *     Next *ListNode
 * }
 */
func mergeTwoLists(l1 *ListNode, l2 *ListNode) *ListNode {
    var nList = &ListNode{0, nil}
    cur := nList

    for l1 != nil && l2 != nil {
        if l1.Val >= l2.Val {
            cur.Next = &ListNode{l2.Val, nil}
            l2 = l2.Next
        } else {
            cur.Next = &ListNode{l1.Val, nil}
            l1 = l1.Next
        }
        cur = cur.Next
    }

    if l1 != nil {
        cur.Next = l1
    }

    if l2 != nil {
        cur.Next = l2
    }

    return nList.Next
}
```

#### 合并K个升序链表

#### 单链表，每N个翻转

#### 链表是否有环

#### 链表：奇数生序，偶数降序

#### 奇偶链表

```go
/**
 * Definition for singly-linked list.
 * type ListNode struct {
 *     Val int
 *     Next *ListNode
 * }
 */
func oddEvenList(head *ListNode) *ListNode {
    if head == nil || head.Next == nil {
        return head
    }

    head2 := head.Next
    p1 := head
    p2 := head2
    for p1.Next != nil && p2.Next != nil {
        p1.Next = p2.Next
        p1 = p1.Next
        p2.Next = p1.Next
        p2 = p2.Next
    }

    p1.Next = head2
    return head
}
```

### 打家劫舍

> 你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。
> 
> 给定一个代表每个房屋存放金额的非负整数数组，计算你 不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。

```go
func rob(nums []int) int {
    if len(nums) == 0 {
        return 0
    }
    dp := make([]int, len(nums) + 2)
    dp[0] = 0
    dp[1] = nums[0]
    for i := 2; i <= len(nums); i++ {
        dp[i] = max(dp[i-2] + nums[i-1], dp[i-1])
    }
    return dp[len(nums)]
}

func max (a, b int) int {
    if a > b {
        return a
    }

    return b
}
```

> 你是一个专业的小偷，计划偷窃沿街的房屋，每间房内都藏有一定的现金。这个地方所有的房屋都围成一圈，这意味着第一个房屋和最后一个房屋是紧挨着的。同时，相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。
> 
> 给定一个代表每个房屋存放金额的非负整数数组，计算你在不触动警报装置的情况下，能够偷窃到的最高金额。

```go
func rob(nums []int) int {
    l := len(nums)
    if l == 1 {
        return nums[0]
    }
    return max(doRob(nums[:l-1]), doRob(nums[1:l]))
}

func doRob(nums []int) int {
    n := len(nums)
    dp := make([]int, n + 2)
    for i := n - 1; i >=0; i-- {
        dp[i] = max(dp[i+1], dp[i+2] + nums[i])
    }

    return dp[0]
}

func max (a, b int) int {
    if a > b {
        return a
    }

    return b
}
```

> 在上次打劫完一条街道之后和一圈房屋后，小偷又发现了一个新的可行窃的地区。这个地区只有一个入口，我们称之为“根”。 除了“根”之外，每栋房子有且只有一个“父“房子与之相连。一番侦察之后，聪明的小偷意识到“这个地方的所有房屋的排列类似于一棵二叉树”。 如果两个直接相连的房子在同一天晚上被打劫，房屋将自动报警。
> 
> 计算在不触动警报的情况下，小偷一晚能够盗取的最高金额。

```go
/**
 * Definition for a binary tree node.
 * type TreeNode struct {
 *     Val int
 *     Left *TreeNode
 *     Right *TreeNode
 * }
 */
func rob(root *TreeNode) int {
    return doRob(root)
}

func doRob(root *TreeNode) int {
    if root == nil {
        return 0
    }

    // 抢
    qSum := root.Val
    if root.Left != nil {
        qSum = qSum + doRob(root.Left.Left) + doRob(root.Left.Right)
    }

    if root.Right != nil {
        qSum = qSum + doRob(root.Right.Left) + doRob(root.Right.Right)
    }

    // 不抢
    nSum := doRob(root.Left) + doRob(root.Right)

    return max(qSum, nSum)
}

func max(a, b int) int {
    if a > b {
        return a
    }

    return b
}
```

## 大数据处理

### 大文件topK

### 其他

sql题，出现过2次及以上相同名字的人的名字

### 正则： 写一个手机号的正则表达式，13开头，11位数

```bash
/^13\d{9}$/
```

### 网络协议

链路： TCP/UDP -> IPv4 -> ARP

从IP地址获取MAC地址要通过ARP协议，是通过在本地发送广播包，也就是“吼”，获得的MAC地址。



#### socket

客户端与服务端建立连接的过程中，服务端先创建一个socket，然后bind、listen，accept

这个socket负责监听客户端的连接，当连接建立之后，服务端的accept就会返回另一个socket。

Note:

监听的socket和真正用来传递数据的socket，是两个socket，一个叫做**监听socket**， 一个叫做**已连接socket**。成功连接建立之后，双方开始通过read和write函数来读写数据，就像往一个文件流里面写东西一样。



